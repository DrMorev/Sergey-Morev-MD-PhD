# Sergey-Morev-MD-PhD
Researcher | Healthcare AI | Human-AI Interaction | Pharmacovigilance background | Writing | AI Evaluation

Building frameworks for trustworthy AI in healthcare and high-stakes environments.

---

### Focus

**AI & Healthcare Reliability**  
Evaluation methodologies â€¢ Safety frameworks â€¢ Drift detection â€¢ Audit protocols

**Human-AI Interaction Research**  
Digital hygiene â€¢ Isolated workers â€¢ Companion AI safety â€¢ Interaction patterns

**Medical Technology Assessment**  
Evidence-based evaluation â€¢ Risk mapping â€¢ Qualification frameworks

---

### My AI Research Workflow: Cross-Platform Agentic Architecture
I employ a human-led, cross-platform agentic research workflow designed to ensure rigor, safety, and reproducibility in high-stakes AI research.
Rather than relying on a single model or perspective, I use a distributed, role-based evaluation pipeline, where frontier LLMs are treated as specialized computational components, each constrained to a clearly defined function.
All synthesis, prioritization, and final decisions remain under explicit human control.
Core Workflow Layers
1. Research & Methodology Validation
Scientific framing and positioning within existing literature gaps
Methodological sanity checks for N=1, longitudinal, and case-based designs
Cross-model triangulation to reduce single-source bias and hallucinations
2. Technical Development & System Architecture
Refactoring experimental logic into production-grade, documented codebases
Design of modular external reasoning scaffolds (e.g., Modular Reasoning Framework)
Interface, API, and artifact consistency checks
3. Safety, QA & Compliance (Adversarial Review Layer)
Systematic stress-testing of safety boundaries and failure modes
Pharmacovigilance-inspired audit logic applied to LLM behavior
Strict Definition-of-Done (DoD) gates before any artifact is finalized
4. Strategic Orchestration & Oversight (Human PI Control)
Scope management and prevention of uncontrolled feature expansion
Cross-architecture output auditing to detect instability and drift
Final synthesis, judgment, and accountability retained by the researcher
Why Cross-Platform?
Specialization: Different model architectures excel at different tasks (reasoning, nuance, robustness).
Behavioral Analysis: Comparing responses across models is critical for AI Safety research.
Redundancy: Prevents hidden failure modes caused by single-model drift or bias.
This workflow is intentionally designed as a reproducible research system, not as conversational or companion-based interaction.

---

### Background

MD/PhD â€” Pediatric surgery, rheumatology  
6+ years pharmacovigilance and drug safety  
Independent researcher in AI evaluation and human-AI interaction

---

### Current Work

- Clinical AI safety evaluation frameworks
- Mental health research: AI companions for isolated workers
- Writing on digital hygiene and human-AI boundaries

---

### LONG-TAIL KEYWORDS

- Clinical AI safety assessment  
- AI reliability testing
- Healthcare LLM deployment
- Medical AI compliance
- LLM drift detection
- Model behavior stability
- AI audit protocols
- Evaluation test suites
- LLM behavior evaluation
- Safety qualification framework

### Open to

Research collaborations â€¢ Consulting â€¢ Advisory roles â€¢ Speaking

ðŸ“§ smorev.research@gmail.com
